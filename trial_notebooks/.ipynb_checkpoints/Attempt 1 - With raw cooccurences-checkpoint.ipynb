{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_fname=\"/home/hank/Backup_data/data/finalex_reuters-cleaned-document_without_zeros.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading documents & Calculating term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " inserting ... 203001 docs, mem= 2.508 Gb"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import sys\n",
    "from utils import get_process_memory\n",
    "\n",
    "M_term_doc = defaultdict(lambda: {})\n",
    "with open(document_fname, encoding='utf-8') as f:\n",
    "    for d, doc in enumerate(f):\n",
    "        tf = Counter(doc.split())\n",
    "        for t, freq in tf.items():\n",
    "            M_term_doc[t][d] = freq\n",
    "        if d % 1000 == 0: \n",
    "            sys.stdout.write('\\r inserting ... %d docs, mem= %.3f Gb' %(d+1, get_process_memory()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing BOC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d300_w8_mf50_c100.csv', '/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d200_w8_mf50_c200.csv', '/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d300_w8_mf50_c300.csv', '/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d200_w8_mf50_c100.csv', '/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d100_w8_mf50_c300.csv', '/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d200_w8_mf50_c300.csv', '/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d100_w8_mf50_c100.csv', '/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d100_w8_mf50_c200.csv', '/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c_d300_w8_mf50_c200.csv']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "word2concept_fname=[ef for ef in glob.glob(\"/home/hank/Desktop/projects/auto_concept_labeling_POC/trained_results/w2c*.csv\")]\n",
    "print(word2concept_fname)\n",
    "print(len(word2concept_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for calculating co-occurence between two terms within same document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cooccurrence(w1, w2):\n",
    "    docs1 = M_term_doc.get(w1, {})\n",
    "    docs2 = M_term_doc.get(w2, {})\n",
    "    cooccurrence = 0\n",
    "    for d1, tf_d1w1 in docs1.items():\n",
    "        tf_d1w2 = docs2.get(d1, 0)\n",
    "        if not tf_d1w2:\n",
    "            continue\n",
    "        cooccurrence += max(tf_d1w1, tf_d1w2)\n",
    "    return cooccurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for calculating sparsity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = lambda x, p: 0 if (not x or p == 0) else pow(sum(v ** p for v in x.values()), 1/p)\n",
    "sparsity = lambda x, m, n, km_over_kn: (km_over_kn - (norm(x,m)/norm(x,n))) / (0.000000000000000001 + km_over_kn - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively calculate sparsity score for words in all of the BOC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2c_d200_w8_mf50_c200_sparsity.csv\n",
      " computing sparsity ... 40000 words in 40069. mem= 3.391 Gb\n",
      "done\n",
      "....w2c_d200_w8_mf50_c200_sparsity.csv created\n",
      "w2c_d300_w8_mf50_c300_sparsity.csv\n",
      " computing sparsity ... 35000 words in 40069. mem= 3.391 Gb...Zero Division Error!\n",
      " computing sparsity ... 40000 words in 40069. mem= 3.391 Gb...Zero Division Error!\n",
      "\n",
      "done\n",
      "....w2c_d300_w8_mf50_c300_sparsity.csv created\n",
      "w2c_d200_w8_mf50_c100_sparsity.csv\n",
      " computing sparsity ... 40000 words in 40069. mem= 3.410 Gb\n",
      "done\n",
      "....w2c_d200_w8_mf50_c100_sparsity.csv created\n",
      "w2c_d100_w8_mf50_c300_sparsity.csv\n",
      " computing sparsity ... 6400 words in 40069. mem= 3.409 Gb...Zero Division Error!\n",
      " computing sparsity ... 9100 words in 40069. mem= 3.409 Gb...Zero Division Error!\n",
      " computing sparsity ... 9400 words in 40069. mem= 3.409 Gb...Zero Division Error!\n",
      "...Zero Division Error!\n",
      "...Zero Division Error!\n",
      " computing sparsity ... 11500 words in 40069. mem= 3.409 Gb...Zero Division Error!\n",
      " computing sparsity ... 13400 words in 40069. mem= 3.409 Gb...Zero Division Error!\n",
      "...Zero Division Error!\n",
      "...Zero Division Error!\n",
      "...Zero Division Error!\n",
      "...Zero Division Error!\n",
      " computing sparsity ... 25500 words in 40069. mem= 3.409 Gb...Zero Division Error!\n",
      " computing sparsity ... 40000 words in 40069. mem= 3.409 Gb\n",
      "done\n",
      "....w2c_d100_w8_mf50_c300_sparsity.csv created\n",
      "w2c_d200_w8_mf50_c300_sparsity.csv\n",
      " computing sparsity ... 7200 words in 40069. mem= 3.407 Gb...Zero Division Error!\n",
      " computing sparsity ... 11200 words in 40069. mem= 3.407 Gb...Zero Division Error!\n",
      " computing sparsity ... 18300 words in 40069. mem= 3.407 Gb...Zero Division Error!\n",
      " computing sparsity ... 19100 words in 40069. mem= 3.407 Gb...Zero Division Error!\n",
      " computing sparsity ... 36900 words in 40069. mem= 3.407 Gb...Zero Division Error!\n",
      "...Zero Division Error!\n",
      " computing sparsity ... 38800 words in 40069. mem= 3.407 Gb...Zero Division Error!\n",
      " computing sparsity ... 40000 words in 40069. mem= 3.407 Gb\n",
      "done\n",
      "....w2c_d200_w8_mf50_c300_sparsity.csv created\n",
      "w2c_d100_w8_mf50_c100_sparsity.csv\n",
      " computing sparsity ... 40000 words in 40069. mem= 3.410 Gb\n",
      "done\n",
      "....w2c_d100_w8_mf50_c100_sparsity.csv created\n",
      "w2c_d100_w8_mf50_c200_sparsity.csv\n",
      " computing sparsity ... 15700 words in 40069. mem= 3.407 Gb...Zero Division Error!\n",
      " computing sparsity ... 40000 words in 40069. mem= 3.407 Gb\n",
      "done\n",
      "....w2c_d100_w8_mf50_c200_sparsity.csv created\n"
     ]
    }
   ],
   "source": [
    "for es in word2concept_fname:\n",
    "    outputname=es.split(\"/\")[-1][:-4]+\"_sparsity.csv\"\n",
    "    print(outputname)\n",
    "    concept_to_words = defaultdict(lambda: [])\n",
    "    with open(es, encoding='utf-8') as f:\n",
    "        for row in f:\n",
    "            cols = row.strip().split(',')\n",
    "            concept = int(cols[-1])\n",
    "            words = ','.join(cols[:-1])\n",
    "            concept_to_words[concept].append(words)\n",
    "    M_cooccurrence = defaultdict(lambda: {})\n",
    "    for concept, words in concept_to_words.items():\n",
    "        #print('concept= %d (%d words) ... ' % (concept, len(words)), end='')\n",
    "        for w1 in words:\n",
    "            for w2 in words:\n",
    "                if w1 <= w2: continue\n",
    "                cooc = cooccurrence(w1, w2)\n",
    "                M_cooccurrence[w1][w2] = cooc\n",
    "                M_cooccurrence[w2][w1] = cooc\n",
    "        #print('done. mem= %.3f Gb' % get_process_memory())\n",
    "    word_to_sparsity = {}\n",
    "\n",
    "    m = 1\n",
    "    n = 2\n",
    "\n",
    "    i_words = 0\n",
    "    n_words = sum((len(words) for words in concept_to_words.values()))\n",
    "\n",
    "    for concept, words in concept_to_words.items():\n",
    "        k = len(words)\n",
    "        km_over_kn = pow(k, 1/m) / pow(k, 1/n)\n",
    "\n",
    "        for word in words:\n",
    "            i_words += 1\n",
    "            if i_words % 100 == 0:\n",
    "                args = (i_words, n_words, get_process_memory())\n",
    "                sys.stdout.write('\\r computing sparsity ... %d words in %d. mem= %.3f Gb' % args)\n",
    "\n",
    "            cooccurrence_vector = M_cooccurrence.get(word, {})\n",
    "\n",
    "            if not cooccurrence_vector:\n",
    "                continue\n",
    "\n",
    "            if len(cooccurrence_vector) == 1:\n",
    "                word_to_sparsity[word] = 1\n",
    "                continue\n",
    "            try:\n",
    "                word_to_sparsity[word] = sparsity(cooccurrence_vector, m, n, km_over_kn)\n",
    "            except ZeroDivisionError:\n",
    "                print(\"...Zero Division Error!\")\n",
    "                word_to_sparsity[word] = -1\n",
    "                continue\n",
    "    print('\\ndone')\n",
    "    get_sparsity = lambda w:word_to_sparsity[w]\n",
    "    get_tf = lambda w:sum(M_term_doc[w].values())\n",
    "    get_df = lambda w:len(M_term_doc[w])\n",
    "    \n",
    "    with open(outputname, \"w\") as f:\n",
    "        for concept, words in concept_to_words.items():\n",
    "            topk_words = sorted(words, key=lambda x:word_to_sparsity[x])\n",
    "            for w in topk_words:\n",
    "                f.write('%d, %s, %.3f, %d, %d\\n' % (concept, w, get_sparsity(w), get_tf(w), get_df(w)))\n",
    "    print('....%s created' % outputname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
